Hadoop(HDFS)安装
	下载
	解压：~/app
	添加HADOOP_HOME/bin到系统环境变量
	修改Hadoop配置文件
		hadoop-env.sh
			export JAVA_HOME=/home/hadoop/app/jdk1.8.0_91

		core-site.xml
			<property>
			    <name>fs.defaultFS</name>
			    <value>hdfs://hadoop000:8020</value>
			</property>

		hdfs-site.xml
			<property>
			    <name>dfs.replication</name>
			    <value>1</value>
			</property>

			<property>
			    <name>hadoop.tmp.dir</name>
			    <value>/home/hadoop/app/tmp</value>
			</property>

		slaves
			hadoop000
	启动HDFS：
		第一次执行的时候一定要格式化文件系统，不要重复执行: hdfs namenode -format
		启动集群：$HADOOP_HOME/sbin/start-dfs.sh
		验证:
			[hadoop@hadoop000 sbin]$ jps
			60002 DataNode
			60171 SecondaryNameNode
			59870 NameNode

			http://192.168.199.233:50070
			如果发现jps ok，但是浏览器不OK？ 十有八九是防火墙问题
			查看防火墙状态：sudo firewall-cmd --state
			关闭防火墙: sudo systemctl stop firewalld.service
			进制防火墙开机启动：



hadoop软件包常见目录说明
	bin：hadoop客户端名单
	etc/hadoop：hadoop相关的配置文件存放目录
	sbin：启动hadoop相关进程的脚本
	share：常用例子


注意：
	start/stop-dfs.sh与hadoop-daemons.sh的关系
	start-dfs.sh =
		hadoop-daemons.sh start namenode
		hadoop-daemons.sh start datanode
		hadoop-daemons.sh start secondarynamenode
	stop-dfs.sh =
		....
